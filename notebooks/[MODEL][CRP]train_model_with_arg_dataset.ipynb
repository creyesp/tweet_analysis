{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from unidecode import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "\n",
    "from common import Lematizator, cleaner, tokenizer, Dataset\n",
    "from common import STOP_WORD_ES\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neutral': 89782, 'negative': 26272, 'positive': 107252})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = '../data/ready/full_spanish_dataset.json'\n",
    "\n",
    "with open(ds_path, 'r') as f:\n",
    "    dataset_raw = json.load(f)\n",
    "\n",
    "c = Counter([k['klass'] for k in dataset_raw])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '4.Denme una mano con RT para exigir q @lanacioncom retire la foto y respete el derecho a la intimidad de @MariaviicToriia su mam√° y hermano.',\n",
       " 'klass': 'neutral',\n",
       " 'id_annotator': '87',\n",
       " 'id': '332473940712751104'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_raw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset()\n",
    "corpus, target = ds.binary_class(dataset_raw, processed=False)\n",
    "corpus_multi, target_multi = ds.multi_class(dataset_raw, processed=False)\n",
    "corpus_multi_lema = Lematizator().fit_transform(corpus_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = [tweet for tweet, klass in zip(corpus_multi, target_multi) if klass==-1]\n",
    "neutral = [tweet for tweet, klass in zip(corpus_multi, target_multi) if klass==0]\n",
    "positive = [tweet for tweet, klass in zip(corpus_multi, target_multi) if klass==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cleaner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feria del libro | dolina se llev√≥ el premio del lector con sus ‚Äúcartas marcadas‚Äù ',\n",
       " 'me encanto la idea de \"cafe pendiente\" que buena iniciativa para argentina, ojala todos los bares se sumen!!! ‚ô•',\n",
       " 'argentina renov√≥ acuerdo que permitir√° exportar a venezuela 10 mil automotores por a√±o ',\n",
       " ' hola mi amorete, te extra√±ooooo',\n",
       " 'el domingo 12 se lanza en la feria del libro de buenos aires la campa√±a de la onu el valiente no es violento,... ',\n",
       " 'verdad?  quien quiere de verdad quiere en silencio, con hechos y nunca con palabras.',\n",
       " 'argentina renov√≥ acuerdo que permitir√° exportar a venezuela 10 mil automotores por a√±o ',\n",
       " 'pablo migliore cerca de la libertad, rt si lo quer√©s de vuelta defendiendo el arco del ',\n",
       " 'unidos en la esperanza!.',\n",
       " '  que sea tierno y me abraze a todo momento.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cleaner(k) for k in positive[100:120:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lo que me hizo reir gast√≥n, no tiene nombre...\n",
      "['lo', 'que', 'me', 'hizo', 'reir', 'gast√≥n', 'no', 'tiene', 'nombre']\n",
      "['hizo', 'reir', 'gast√≥n', 'nombre']\n"
     ]
    }
   ],
   "source": [
    "tweet = corpus[1].lower()\n",
    "print(tweet)\n",
    "print(tokenizer(tweet))\n",
    "print([k for k in tokenizer(tweet) if k not in STOP_WORD_ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'el', 'los', 'hombres', 'ir√°n', 'a', 'la', 'luna']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer('en el 2001 los hombres ir√°n a la luna'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA principal ADJETIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "adj_nltk = Counter([token for k in corpus[:n_samples] for (token, pos) in nltk.pos_tag(tokenizer(k)) if pos in ['JJ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('un', 15),\n",
       " ('una', 11),\n",
       " ('las', 4),\n",
       " ('nos', 3),\n",
       " ('se', 3),\n",
       " ('los', 3),\n",
       " ('lat', 2),\n",
       " ('por', 2),\n",
       " ('ser√°n', 2),\n",
       " ('incre√≠ble', 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_nltk.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = ['ADJ', 'ADV', 'VERB']\n",
    "pos = ['ADJ']\n",
    "adj_spacy = Counter([k.lemma_ for tw in corpus[:100] for k in nlp(tw) if k.pos_ in pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Buen', 6),\n",
       " ('‚ô•', 3),\n",
       " ('primario', 2),\n",
       " ('‚Ä¶', 2),\n",
       " ('retirar', 2),\n",
       " ('incre√≠ble', 2),\n",
       " ('ins√≥lito', 2),\n",
       " ('mejorar', 2),\n",
       " ('peor', 2),\n",
       " ('necesario', 2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_spacy.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_pos(speech):\n",
    "    pos = 'ADJ'\n",
    "    filtered_speech = [\n",
    "        ent.lemma_.lower() \n",
    "        for doc in nlp.pipe([cleaner(k) for k in positive],\n",
    "                             disable=[\"parser\", \"ner\", 'textcat'],\n",
    "                             n_process=-1) \n",
    "        for ent in doc if ent.pos_==pos]\n",
    "    \n",
    "    return filtered_speech\n",
    "\n",
    "adj_pos = filter_by_pos(positive)\n",
    "adj_neutral = filter_by_pos(neutral)\n",
    "adj_neg = filter_by_pos(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = list({unidecode(k) for k,_ in Counter(adj_neg + adj_pos + adj_neutral).most_common(5000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'amor!!gracias',\n",
       " 'suculento',\n",
       " 'intacto',\n",
       " 'castulo',\n",
       " 'paralelo',\n",
       " 'adjunto',\n",
       " 'tenir',\n",
       " '-no',\n",
       " 'sentarse',\n",
       " 'exactamente',\n",
       " 'explotar',\n",
       " 'incesante',\n",
       " 'eeeeeeeeeeeeeeeeeenooooorme',\n",
       " 'jordano',\n",
       " 'informativo',\n",
       " 'inteligente',\n",
       " 'monedero',\n",
       " 'desinformado',\n",
       " 'indiscriminado',\n",
       " 'chingonas',\n",
       " 'irreductible',\n",
       " 'celiaco',\n",
       " 'matrimonial',\n",
       " 'resacar',\n",
       " 'informarse',\n",
       " 'intubar',\n",
       " 'revelador',\n",
       " 'p.d',\n",
       " 'resfriar',\n",
       " 'tequiiero',\n",
       " 'pillar',\n",
       " 'artico',\n",
       " 'ceramica',\n",
       " 'tenebroso',\n",
       " 'colapsar',\n",
       " 'riguroso',\n",
       " 'acojonar',\n",
       " 'funcional',\n",
       " 'blancanieves',\n",
       " 'vecinal',\n",
       " 'seco',\n",
       " 'someter',\n",
       " 'repetir',\n",
       " 'hidrico',\n",
       " 'tequiero',\n",
       " 'ritmico',\n",
       " 'oso',\n",
       " 'jo']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to num vector\n",
    "BOW = Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(y_train, y_train_pred, y_test, y_test_pred):\n",
    "    acc_train = accuracy_score(y_train, y_train_pred)\n",
    "    acc_test = accuracy_score(y_test, y_test_pred)\n",
    "    print(f'Accuracy train: {acc_train}')\n",
    "    print(f'Accuracy test: {acc_test}')\n",
    "    print(f'Confusion matrx train:\\n{confusion_matrix(y_train, y_train_pred)}')\n",
    "    print(f'Confusion matrx test:\\n{confusion_matrix(y_test, y_test_pred)}')\n",
    "    print(f'Report train:\\n{classification_report(y_train, y_train_pred)}')\n",
    "    print(f'Report test:\\n{classification_report(y_test, y_test_pred)}')\n",
    "    \n",
    "def train_and_test_model(clf, x_train, y_train, x_test, y_test):\n",
    "    clf.fit(x_train, y_train);\n",
    "    y_train_pred = clf.predict(x_train)\n",
    "    y_test_pred = clf.predict(x_test)\n",
    "    \n",
    "    test_model(y_train, y_train_pred, y_test, y_test_pred)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing = HashingVectorizer(\n",
    "    analyzer = \"word\",\n",
    "    n_features=1000,\n",
    "#     tokenizer=tokenizer_stemmer,\n",
    "    preprocessor=None,\n",
    "    #  stop_words=stopwords.words(\"spanish\"),\n",
    "    binary=False,\n",
    "    strip_accents='unicode',\n",
    "    encoding='utf-8',\n",
    "    ngram_range=(1,3), )\n",
    "\n",
    "vectorizer = CountVectorizer(  \n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenizer,\n",
    "    strip_accents='unicode',\n",
    "    preprocessor=cleaner,\n",
    "    lowercase = True,\n",
    "    stop_words = STOP_WORD_ES,\n",
    "    max_features=5000,\n",
    "#     min_df = 0.,\n",
    "#     max_df = 1.9,\n",
    "    ngram_range=(1, 3),\n",
    "    binary=False,\n",
    ")\n",
    "\n",
    "vect_custom = CountVectorizer(  \n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenizer,\n",
    "    strip_accents='unicode',\n",
    "    preprocessor=cleaner,\n",
    "    lowercase = True,\n",
    "    stop_words = STOP_WORD_ES,\n",
    "    max_features=5000,\n",
    "#     min_df = 0.,\n",
    "#     max_df = 1.9,\n",
    "    ngram_range=(1, 3),\n",
    "    binary=False,\n",
    "    vocabulary=voc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['', 'posicional'], dtype='<U27')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_custom.fit(corpus[:10])\n",
    "vect_custom.inverse_transform(corpus[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bin, x_test_bin, y_train_bin, y_test_bin =  \\\n",
    "    train_test_split(corpus, target, stratify=target, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.6883045151143523\n",
      "Accuracy test: 0.6497659614304437\n",
      "Confusion matrx train:\n",
      "[[13826  7192]\n",
      " [26103 59698]]\n",
      "Confusion matrx test:\n",
      "[[ 2929  2325]\n",
      " [ 7028 14423]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.66      0.45     21018\n",
      "           1       0.89      0.70      0.78     85801\n",
      "\n",
      "    accuracy                           0.69    106819\n",
      "   macro avg       0.62      0.68      0.62    106819\n",
      "weighted avg       0.79      0.69      0.72    106819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps=Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                      (\"clf\",  LogisticRegressionCV(cv=3, class_weight='balanced', n_jobs=-1))])\n",
    "logit_bin_pipeline = train_and_test_model(steps, x_train_bin, y_train_bin, x_test_bin, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_bin[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬°Vamos #APorLaD√©cima! Conoce la historia de las victorias del Real Madrid en la UCL: bit.ly/1i10lZRpic.twitter.com/omTDc1chu5\n",
      "probability: [[0.01785559 0.98214441]], class: [1]\n"
     ]
    }
   ],
   "source": [
    "tweet = x_test_bin[2]\n",
    "print(tweet)\n",
    "print(f'probability: {logit_bin_pipeline.predict_proba([tweet])}, class: {logit_bin_pipeline.predict([tweet])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lamatizated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_raw, x_test_raw, y_train_raw, y_test_raw =  \\\n",
    "    train_test_split(corpus_multi, target_multi, stratify=target_multi, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lema, x_test_lema, y_train_lema, y_test_lema =  \\\n",
    "    train_test_split(corpus_multi_lema, target_multi, stratify=target_multi, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5339558003627326\n",
      "Accuracy test: 0.5053289149612646\n",
      "Confusion matrx train:\n",
      "[[11659  4103  5256]\n",
      " [13747 40254 17824]\n",
      " [21412 20914 43475]]\n",
      "Confusion matrx test:\n",
      "[[ 2514  1179  1561]\n",
      " [ 3536  9601  4820]\n",
      " [ 5454  5543 10454]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.25      0.55      0.34     21018\n",
      "           0       0.62      0.56      0.59     71825\n",
      "           1       0.65      0.51      0.57     85801\n",
      "\n",
      "    accuracy                           0.53    178644\n",
      "   macro avg       0.51      0.54      0.50    178644\n",
      "weighted avg       0.59      0.53      0.55    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                        ('clf', LogisticRegressionCV(cv=3,\n",
    "                                                     class_weight='balanced',\n",
    "                                                     n_jobs=-1,\n",
    "                                                     solver='lbfgs',\n",
    "                                                     multi_class='auto'))])\n",
    "logit_multi_pipeline = train_and_test_model(steps, x_train_raw, y_train_raw, x_test_raw, y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SetteSettamen @Conpdepau ya veo ya.... üò°üò°üò°üò° a ti tambien sette que te tiro un botellin a la cabeza eh ajajjajaja\n",
      "probability: [[0.6269805  0.0983468  0.27467269]], class: [-1]\n"
     ]
    }
   ],
   "source": [
    "tweet = x_test_raw[3]\n",
    "print(tweet)\n",
    "print(f'probability: {logit_multi_pipeline.predict_proba([tweet])}, class: {logit_multi_pipeline.predict([tweet])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION**: We need to pay mora atention to vocabulary to improve the performance. there are a lot of word with the same meaning, pluran and singular, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abajo',\n",
       " 'arte',\n",
       " 'caminar',\n",
       " 'conmigo',\n",
       " 'dejas',\n",
       " 'efe',\n",
       " 'fav si',\n",
       " 'hacerme',\n",
       " 'israel√≠',\n",
       " 'madrid',\n",
       " 'muchas ganas',\n",
       " 'palacio',\n",
       " 'pongan',\n",
       " 'ranking',\n",
       " 'seg√∫n',\n",
       " 'terminal',\n",
       " 'versi√≥n']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_multi_pipeline.steps[0][1].get_feature_names()[::300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.6011285013770403\n",
      "Accuracy test: 0.5791276700550804\n",
      "Confusion matrx train:\n",
      "[[ 1074  5324 14620]\n",
      " [  374 39363 32088]\n",
      " [  486 18364 66951]]\n",
      "Confusion matrx test:\n",
      "[[  210  1346  3698]\n",
      " [   91  9371  8495]\n",
      " [  145  5022 16284]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.05      0.09     21018\n",
      "           0       0.62      0.55      0.58     71825\n",
      "           1       0.59      0.78      0.67     85801\n",
      "\n",
      "    accuracy                           0.60    178644\n",
      "   macro avg       0.59      0.46      0.45    178644\n",
      "weighted avg       0.60      0.60      0.57    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                        ('clf', LogisticRegressionCV(cv=3, class_weight=None, n_jobs=-1, solver='lbfgs', multi_class='auto'))])\n",
    "unbalanced_logit_multi_pipeline = train_and_test_model(steps, x_train_raw, y_train_raw, x_test_raw, y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the hiperparameters (Very simple because of memory issues)\n",
    "# hiperparam_log_multi_pipeline = {  \n",
    "#     \"processor__max_features\":[100, 1000, 3000, 5000],\n",
    "#     \"processor__ngram_range\":[(1, 1), (1, 2), (1, 3),],\n",
    "#     \"processor__binary\":[True, False],\n",
    "# #     \"clf__cv\":[3, 5],\n",
    "# #     \"clf__class_weight\":['balanced', None]\",\n",
    "#     }\n",
    "\n",
    "# log_grid_search = GridSearchCV(estimator=log_multi_pipeline,\n",
    "#                               param_grid=hiperparam_log_multi_pipeline,\n",
    "#                               scoring=\"accuracy\",\n",
    "#                               cv=2,\n",
    "#                               n_jobs=-1\n",
    "#                              )\n",
    "        \n",
    "\n",
    "# #We train the model\n",
    "# log_grid_search.fit(x_train, y_train)\n",
    "\n",
    "# #This will take a very long time\n",
    "\n",
    "# print(f'best score: {log_grid_search.best_score_}')\n",
    "\n",
    "# print(f'score: {log_grid_search.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5930565818051544\n",
      "Accuracy test: 0.5811651963637992\n",
      "Confusion matrx train:\n",
      "[[ 3474  5038 12506]\n",
      " [ 2691 40611 28523]\n",
      " [ 3479 20461 61861]]\n",
      "Confusion matrx test:\n",
      "[[  746  1258  3250]\n",
      " [  648 10000  7309]\n",
      " [  881  5360 15210]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.36      0.17      0.23     21018\n",
      "           0       0.61      0.57      0.59     71825\n",
      "           1       0.60      0.72      0.66     85801\n",
      "\n",
      "    accuracy                           0.59    178644\n",
      "   macro avg       0.53      0.48      0.49    178644\n",
      "weighted avg       0.58      0.59      0.58    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_mnb = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                            ('clf', MultinomialNB())])\n",
    "mnb_multi_pipeline = train_and_test_model(steps_mnb, x_train_lema, y_train_lema, x_test_lema, y_test_lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.59251920019704\n",
      "Accuracy test: 0.5778290269132595\n",
      "Confusion matrx train:\n",
      "[[ 3056  5151 12811]\n",
      " [ 2134 40206 29485]\n",
      " [ 2843 20370 62588]]\n",
      "Confusion matrx test:\n",
      "[[  604  1278  3372]\n",
      " [  560  9779  7618]\n",
      " [  744  5283 15424]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      0.15      0.21     21018\n",
      "           0       0.61      0.56      0.58     71825\n",
      "           1       0.60      0.73      0.66     85801\n",
      "\n",
      "    accuracy                           0.59    178644\n",
      "   macro avg       0.53      0.48      0.48    178644\n",
      "weighted avg       0.58      0.59      0.58    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_mnb_raw = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                            ('clf', MultinomialNB())])\n",
    "mnb_multi_pipeline_raw = train_and_test_model(steps_mnb_raw, x_train_raw, y_train_raw, x_test_raw, y_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, -1,  0,  1,  0,  1,  1,  1,  1,  1, -1,  1,  1,  0,  1,\n",
       "        1,  1,  1,  1,  0, -1,  0,  0,  1,  1,  1,  1,  0,  1,  1,  1,  1,\n",
       "        1,  1,  0,  1,  1,  1, -1,  0, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        0,  1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_multi_pipeline_raw.predict([k for k , p in zip(x_test_raw, y_test_raw) if p==-1][::100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BernulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5906215713933858\n",
      "Accuracy test: 0.5782544444942009\n",
      "Confusion matrx train:\n",
      "[[ 3696  4700 12622]\n",
      " [ 3039 38960 29826]\n",
      " [ 3979 18967 62855]]\n",
      "Confusion matrx test:\n",
      "[[  807  1182  3265]\n",
      " [  753  9565  7639]\n",
      " [ 1045  4952 15454]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.34      0.18      0.23     21018\n",
      "           0       0.62      0.54      0.58     71825\n",
      "           1       0.60      0.73      0.66     85801\n",
      "\n",
      "    accuracy                           0.59    178644\n",
      "   macro avg       0.52      0.48      0.49    178644\n",
      "weighted avg       0.58      0.59      0.58    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_bernulli = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                          ('clf', BernoulliNB())])\n",
    "bernulli_multi_pipeline = train_and_test_model(steps_bernulli, x_train_lema, y_train_lema, x_test_lema, y_test_lema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/software/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5925863728980543\n",
      "Accuracy test: 0.5596480229277686\n",
      "Confusion matrx train:\n",
      "[[ 7251  4468  9299]\n",
      " [ 6048 40913 24864]\n",
      " [ 8707 19396 57698]]\n",
      "Confusion matrx test:\n",
      "[[ 1468  1235  2551]\n",
      " [ 1565  9710  6682]\n",
      " [ 2388  5246 13817]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.34      0.34     21018\n",
      "           0       0.63      0.57      0.60     71825\n",
      "           1       0.63      0.67      0.65     85801\n",
      "\n",
      "    accuracy                           0.59    178644\n",
      "   macro avg       0.53      0.53      0.53    178644\n",
      "weighted avg       0.59      0.59      0.59    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_svc = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                            ('clf', LinearSVC(class_weight='balanced'))])\n",
    "svc_multi_pipeline = train_and_test_model(steps_svc, x_train_lema, y_train_lema, x_test_lema, y_test_lema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5886175858131255\n",
      "Accuracy test: 0.5552371143253773\n",
      "Confusion matrx train:\n",
      "[[ 7000  4694  9324]\n",
      " [ 5817 40672 25336]\n",
      " [ 8573 19747 57481]]\n",
      "Confusion matrx test:\n",
      "[[ 1449  1270  2535]\n",
      " [ 1523  9577  6857]\n",
      " [ 2304  5375 13772]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.33      0.33      0.33     21018\n",
      "           0       0.62      0.57      0.59     71825\n",
      "           1       0.62      0.67      0.65     85801\n",
      "\n",
      "    accuracy                           0.59    178644\n",
      "   macro avg       0.53      0.52      0.52    178644\n",
      "weighted avg       0.59      0.59      0.59    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps_svc_raw = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                            ('clf', LinearSVC(class_weight='balanced'))])\n",
    "svc_multi_pipeline_raw = train_and_test_model(steps_svc_raw, x_train_raw, y_train_raw, x_test_raw, y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['social caer', 'seguridad social caer', 'potter', 'telefono',\n",
       "       'formaci√≥n bolsa', 'horapunta', 'zumbido', 'deprimir', 'ice',\n",
       "       'eternoalfredo leyenda', 'voto perd√≥name claudio', 'keylor ser',\n",
       "       'temporada youtu', 'temporada youtu be', 'registrar subir agostar',\n",
       "       'dioooos', 'considerar comer', 'vuelve campe√≥n', 'as ser',\n",
       "       'respirar hondo', 'horrible', 'aburrimiento', 'personar agostar',\n",
       "       'buenos d√≠a familia', 'cst', 'charlie sheen', 'maril√≥ montero',\n",
       "       'unir causar', 'luchar vencer', 'ardiente di st√©fano', 'alcaraz',\n",
       "       'casar real madrid', 'pobrecillo', 'campe√≥n copa',\n",
       "       'in mexico city', 'ocho ma√±ana', 'reino unido',\n",
       "       'parir subir agostar', 'mesar c√°rcel',\n",
       "       'retar alsicebucketchallenge', 'play store', 'casar real', 'mun',\n",
       "       'bucket challenge', 'prohibir miembro',\n",
       "       'internacional ciudad m√©xico', 'casillas saber', 'retar haber',\n",
       "       'falto respetar', 'plancha'], dtype='<U35')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = svc_multi_pipeline.steps[-1][1].coef_[0,:]\n",
    "vocb = np.array(svc_multi_pipeline.steps[0][1].get_feature_names())\n",
    "vocb[np.argsort(arr)[-50:]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/software/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/home/cesar/software/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.5994883679272743\n",
      "Accuracy test: 0.5814562715507591\n",
      "Confusion matrx train:\n",
      "[[ 3418  5502 12098]\n",
      " [ 2526 43089 26210]\n",
      " [ 3258 21955 60588]]\n",
      "Confusion matrx test:\n",
      "[[  723  1406  3125]\n",
      " [  617 10451  6889]\n",
      " [  844  5812 14795]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.16      0.23     21018\n",
      "           0       0.61      0.60      0.61     71825\n",
      "           1       0.61      0.71      0.66     85801\n",
      "\n",
      "    accuracy                           0.60    178644\n",
      "   macro avg       0.53      0.49      0.50    178644\n",
      "weighted avg       0.58      0.60      0.59    178644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(\n",
    "    estimators=[('mnb', MultinomialNB()),\n",
    "                ('bernulli', BernoulliNB()),\n",
    "                ('lr', LogisticRegression(solver='lbfgs', multi_class='auto')),\n",
    "                ('svc', LinearSVC())\n",
    "               ],\n",
    "    voting='hard',\n",
    "    n_jobs=None, )\n",
    "steps_voting = Pipeline(steps=[('processor', clone(vectorizer)),\n",
    "                            ('voting', voting),\n",
    "                            ])\n",
    "ensamble_multi_pipeline = train_and_test_model(steps_voting, x_train_lema, y_train_lema, x_test_lema, y_test_lema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing models with artificial tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = ['la concha de la lora',\n",
    "         'que mal dia que tuve hoy',\n",
    "         'odio ir a la escuela los viernes',\n",
    "         'las noticias informan',\n",
    "         'que mal todo esto',\n",
    "         'buen d√≠a!!! te deseo lo mejor',\n",
    "         'mal mal mal mal',\n",
    "         'los capitalistas son una basura',\n",
    "         'los comunistas son lo mejor',\n",
    "         'los medios de comunicaci√≥n mienten'\n",
    "\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_bin_pipeline.predict(Lematizator().fit_transform(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1,  0, -1,  1, -1, -1,  1, -1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_multi_pipeline.predict(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1,  1,  1, -1,  1,  1,  0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_multi_pipeline.predict(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pos = unbalanced_logit_multi_pipeline.predict(x_test_raw)\n",
    "pred_nn = logit_bin_pipeline.predict(x_test_raw) - 1\n",
    "result = np.where(pred_pos == 1, pred_pos, pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.15      0.19      0.17      5254\n",
      "           0       0.61      0.32      0.42     17957\n",
      "           1       0.57      0.76      0.65     21451\n",
      "\n",
      "    accuracy                           0.51     44662\n",
      "   macro avg       0.44      0.42      0.41     44662\n",
      "weighted avg       0.54      0.51      0.50     44662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_raw, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.47      0.04      0.07      5254\n",
      "           0       0.60      0.52      0.56     17957\n",
      "           1       0.57      0.76      0.65     21451\n",
      "\n",
      "    accuracy                           0.58     44662\n",
      "   macro avg       0.55      0.44      0.43     44662\n",
      "weighted avg       0.57      0.58      0.55     44662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_raw, pred_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/linear/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/logit_bin_pipeline_raw.joblib']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_binary_file = os.path.join(model_path, 'logit_bin_pipeline_raw.joblib')\n",
    "joblib.dump(logit_bin_pipeline, logit_binary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/logit_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_multi_file = os.path.join(model_path, 'logit_multi_pipeline.joblib')\n",
    "if not logit_multi_pipeline.steps[0][0]=='lematizator':\n",
    "    logit_multi_pipeline.steps.insert(0, ('lematizator', Lematizator()))\n",
    "joblib.dump(logit_multi_pipeline, logit_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/logit_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_multi_raw_file = os.path.join(model_path, 'logit_multi_pipeline_raw.joblib')\n",
    "joblib.dump(logit_multi_pipeline, logit_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/mnb_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_multi_file = os.path.join(model_path, 'mnb_multi_pipeline.joblib')\n",
    "if not mnb_multi_pipeline.steps[0][0]=='lematizator':\n",
    "    mnb_multi_pipeline.steps.insert(0, ('lematizator', Lematizator()))\n",
    "joblib.dump(mnb_multi_pipeline, mnb_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/bernulli_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernulli_multi_file = os.path.join(model_path, 'bernulli_multi_pipeline.joblib')\n",
    "if not bernulli_multi_pipeline.steps[0][0]=='lematizator':\n",
    "    bernulli_multi_pipeline.steps.insert(0, ('lematizator', Lematizator()))\n",
    "joblib.dump(bernulli_multi_pipeline, bernulli_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/svc_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_multi_file = os.path.join(model_path, 'svc_multi_pipeline.joblib')\n",
    "if not svc_multi_pipeline.steps[0][0]=='lematizator':\n",
    "    svc_multi_pipeline.steps.insert(0, ('lematizator', Lematizator()))\n",
    "joblib.dump(svc_multi_pipeline, svc_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/svc_multi_pipeline_raw.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_multi_file_raw = os.path.join(model_path, 'svc_multi_pipeline_raw.joblib')\n",
    "joblib.dump(svc_multi_pipeline_raw, svc_multi_file_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/linear/ensemble_multi_pipeline.joblib']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensamble_multi_file = os.path.join(model_path, 'ensemble_multi_pipeline.joblib')\n",
    "if not ensamble_multi_pipeline.steps[0][0]=='lematizator':\n",
    "    ensamble_multi_pipeline.steps.insert(0, ('lematizator', Lematizator()))\n",
    "joblib.dump(ensamble_multi_pipeline, ensamble_multi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
