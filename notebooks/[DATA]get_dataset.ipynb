{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json \n",
    "import tweepy\n",
    "import ijson\n",
    "from pprint import pprint\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../credentials/twitter_credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "auth = tweepy.OAuthHandler(credentials['consumer_key'], credentials['consumer_secret'])\n",
    "auth.set_access_token(credentials['token'], credentials['token_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, timeout=60*5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitide = -34.883611\n",
    "longitude = -56.181944\n",
    "radius = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocode search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 21:20:46 | es |  eduregueira | TE AMO SUSANA DISTANCIA   https://t.co/eHstTlKKhY\n",
      "2020-04-09 21:20:46 | es |  FedeAbel1899 | Los Arios son mejores que los judíos, pero ustedes ya están listos para la exterminación\n",
      "\n",
      "-Adolf Hitler, 1939\n",
      "2020-04-09 21:20:46 | es |  jaimenievesdiz | RT @Solineszunin: @ChCarreraLeal @jaimenievesdiz En lo que sea, no. Empiecen a señalar, enfáticamente, en que sí y en qué no.\n",
      "2020-04-09 21:20:46 | es |  juangandolfi | @Gestoriadeleste @Miguelorenzoni Las obras que cumplan los protocolos abrirán obvio, las que no, no, tendrán que ajustarse a protocolo.  Lo que se levanta es la licencia, la idea es que arranquen.\n",
      "2020-04-09 21:20:44 | es |  YoriichiTsugi | El primer top 3 del dia y fue porque un loco me saco las fichas paora que no me salieran, se mamo\n"
     ]
    }
   ],
   "source": [
    "n_items = 5\n",
    "uy_tweets = tweepy.Cursor(api.search, geocode=f\"{latitide},{longitude},{radius}km\", tweet_mode='extended')\n",
    "\n",
    "for tweet in uy_tweets.items(n_items):\n",
    "    print(f'{tweet.created_at} | {tweet.lang} |  {tweet.user.screen_name} | {tweet.full_text}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _retrieve_tweet(tweet):\n",
    "    if hasattr(tweet, 'retweeted_status'):\n",
    "        tweet=tweet.retweeted_status._json\n",
    "    else:\n",
    "        tweet=tweet._json\n",
    "    return tweet\n",
    "\n",
    "def search_word(search_txt, n_items=None, until_date=None,\n",
    "                latitide=None, longitude=None, radius=None, verbose=True, **kwargs):\n",
    "    \"\"\"Retrieve tweets.\"\"\"\n",
    "    if latitide and longitude and radius:\n",
    "        uy_tweets = tweepy.Cursor(api.search,\n",
    "                                  q=search_txt,\n",
    "                                  until=until_date,\n",
    "                                  geocode=f\"{latitide},{longitude},{radius}km\",\n",
    "                                  tweet_mode='extended',\n",
    "                                  **kwargs,\n",
    "                                 )\n",
    "    else:\n",
    "        uy_tweets = tweepy.Cursor(api.search,\n",
    "                                  q=search_txt,\n",
    "                                  until=until_date,\n",
    "                                  tweet_mode='extended',\n",
    "                                  **kwargs)\n",
    "\n",
    "    tweets = []\n",
    "    try:\n",
    "        if n_items:\n",
    "            for idx, tweet in enumerate(uy_tweets.items(n_items)):\n",
    "                tweets.append(_retrieve_tweet(tweet))\n",
    "                if not idx % 100:\n",
    "                    print(f'retrieve {idx} tweets')\n",
    "        else:\n",
    "            for idx, tweet in enumerate(uy_tweets.items()):\n",
    "                tweets.append(_retrieve_tweet(tweet))\n",
    "                if not idx % 100:\n",
    "                    print(f'retrieve {idx} tweets')\n",
    "    except Exception as e:\n",
    "        logging.info('Unexpected error, returning partials tweets')\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 0 tweets\n",
      "retrieve 100 tweets\n",
      "retrieve 200 tweets\n",
      "retrieve 300 tweets\n",
      "retrieve 400 tweets\n",
      "retrieve 500 tweets\n",
      "retrieve 600 tweets\n",
      "retrieve 700 tweets\n",
      "retrieve 800 tweets\n",
      "retrieve 900 tweets\n",
      "retrieve 1000 tweets\n",
      "retrieve 1100 tweets\n",
      "retrieve 1200 tweets\n",
      "retrieve 1300 tweets\n",
      "retrieve 1400 tweets\n",
      "retrieve 1500 tweets\n",
      "retrieve 1600 tweets\n",
      "retrieve 1700 tweets\n",
      "retrieve 1800 tweets\n",
      "retrieve 1900 tweets\n",
      "retrieve 2000 tweets\n",
      "retrieve 2100 tweets\n",
      "retrieve 2200 tweets\n",
      "retrieve 2300 tweets\n",
      "retrieve 2400 tweets\n",
      "retrieve 2500 tweets\n",
      "retrieve 2600 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 2700 tweets\n",
      "retrieve 2800 tweets\n",
      "retrieve 2900 tweets\n",
      "retrieve 3000 tweets\n",
      "retrieve 3100 tweets\n",
      "retrieve 3200 tweets\n",
      "retrieve 3300 tweets\n",
      "retrieve 3400 tweets\n",
      "retrieve 3500 tweets\n",
      "retrieve 3600 tweets\n",
      "retrieve 3700 tweets\n",
      "retrieve 3800 tweets\n",
      "retrieve 3900 tweets\n",
      "retrieve 4000 tweets\n",
      "retrieve 4100 tweets\n",
      "retrieve 4200 tweets\n",
      "retrieve 4300 tweets\n",
      "retrieve 4400 tweets\n",
      "retrieve 4500 tweets\n",
      "retrieve 4600 tweets\n",
      "retrieve 4700 tweets\n",
      "retrieve 4800 tweets\n",
      "retrieve 4900 tweets\n",
      "retrieve 5000 tweets\n",
      "retrieve 5100 tweets\n",
      "retrieve 5200 tweets\n",
      "retrieve 5300 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 5400 tweets\n",
      "retrieve 5500 tweets\n",
      "retrieve 5600 tweets\n",
      "retrieve 5700 tweets\n",
      "retrieve 5800 tweets\n",
      "retrieve 5900 tweets\n",
      "retrieve 6000 tweets\n",
      "retrieve 6100 tweets\n",
      "retrieve 6200 tweets\n",
      "retrieve 6300 tweets\n",
      "retrieve 6400 tweets\n",
      "retrieve 6500 tweets\n",
      "retrieve 6600 tweets\n",
      "retrieve 6700 tweets\n",
      "retrieve 6800 tweets\n",
      "retrieve 6900 tweets\n",
      "retrieve 7000 tweets\n",
      "retrieve 7100 tweets\n",
      "retrieve 7200 tweets\n",
      "retrieve 7300 tweets\n",
      "retrieve 7400 tweets\n",
      "retrieve 7500 tweets\n",
      "retrieve 7600 tweets\n",
      "retrieve 7700 tweets\n",
      "retrieve 7800 tweets\n",
      "retrieve 7900 tweets\n",
      "retrieve 8000 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 8100 tweets\n",
      "retrieve 8200 tweets\n",
      "retrieve 8300 tweets\n",
      "retrieve 8400 tweets\n",
      "retrieve 8500 tweets\n",
      "retrieve 8600 tweets\n",
      "retrieve 8700 tweets\n",
      "retrieve 8800 tweets\n",
      "retrieve 8900 tweets\n",
      "retrieve 9000 tweets\n",
      "retrieve 9100 tweets\n",
      "retrieve 9200 tweets\n",
      "retrieve 9300 tweets\n",
      "retrieve 9400 tweets\n",
      "retrieve 9500 tweets\n",
      "retrieve 9600 tweets\n",
      "retrieve 9700 tweets\n",
      "retrieve 9800 tweets\n",
      "retrieve 9900 tweets\n",
      "retrieve 10000 tweets\n",
      "retrieve 10100 tweets\n",
      "retrieve 10200 tweets\n",
      "retrieve 10300 tweets\n",
      "retrieve 10400 tweets\n",
      "retrieve 10500 tweets\n",
      "retrieve 10600 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 10700 tweets\n",
      "retrieve 10800 tweets\n",
      "retrieve 10900 tweets\n",
      "retrieve 11000 tweets\n",
      "retrieve 11100 tweets\n",
      "retrieve 11200 tweets\n",
      "retrieve 11300 tweets\n",
      "retrieve 11400 tweets\n",
      "retrieve 11500 tweets\n",
      "retrieve 11600 tweets\n",
      "retrieve 11700 tweets\n",
      "retrieve 11800 tweets\n",
      "retrieve 11900 tweets\n",
      "retrieve 12000 tweets\n",
      "retrieve 12100 tweets\n",
      "retrieve 12200 tweets\n",
      "retrieve 12300 tweets\n",
      "retrieve 12400 tweets\n",
      "retrieve 12500 tweets\n",
      "retrieve 12600 tweets\n",
      "retrieve 12700 tweets\n",
      "retrieve 12800 tweets\n",
      "retrieve 12900 tweets\n",
      "retrieve 13000 tweets\n",
      "retrieve 13100 tweets\n",
      "retrieve 13200 tweets\n",
      "retrieve 13300 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 13400 tweets\n",
      "retrieve 13500 tweets\n",
      "retrieve 13600 tweets\n",
      "retrieve 13700 tweets\n",
      "retrieve 13800 tweets\n",
      "retrieve 13900 tweets\n",
      "retrieve 14000 tweets\n",
      "retrieve 14100 tweets\n",
      "retrieve 14200 tweets\n",
      "retrieve 14300 tweets\n",
      "retrieve 14400 tweets\n",
      "retrieve 14500 tweets\n",
      "retrieve 14600 tweets\n",
      "retrieve 14700 tweets\n",
      "retrieve 14800 tweets\n",
      "retrieve 14900 tweets\n",
      "retrieve 15000 tweets\n",
      "retrieve 15100 tweets\n",
      "retrieve 15200 tweets\n",
      "retrieve 15300 tweets\n",
      "retrieve 15400 tweets\n",
      "retrieve 15500 tweets\n",
      "retrieve 15600 tweets\n",
      "retrieve 15700 tweets\n",
      "retrieve 15800 tweets\n",
      "retrieve 15900 tweets\n",
      "retrieve 16000 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 16100 tweets\n",
      "retrieve 16200 tweets\n",
      "retrieve 16300 tweets\n",
      "retrieve 16400 tweets\n",
      "retrieve 16500 tweets\n",
      "retrieve 16600 tweets\n",
      "retrieve 16700 tweets\n",
      "retrieve 16800 tweets\n",
      "retrieve 16900 tweets\n",
      "retrieve 17000 tweets\n",
      "retrieve 17100 tweets\n",
      "retrieve 17200 tweets\n",
      "retrieve 17300 tweets\n",
      "retrieve 17400 tweets\n",
      "retrieve 17500 tweets\n",
      "retrieve 17600 tweets\n",
      "retrieve 17700 tweets\n",
      "retrieve 17800 tweets\n",
      "retrieve 17900 tweets\n",
      "retrieve 18000 tweets\n",
      "retrieve 18100 tweets\n",
      "retrieve 18200 tweets\n",
      "retrieve 18300 tweets\n",
      "retrieve 18400 tweets\n",
      "retrieve 18500 tweets\n",
      "retrieve 18600 tweets\n",
      "retrieve 18700 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 18800 tweets\n",
      "retrieve 18900 tweets\n",
      "retrieve 19000 tweets\n",
      "retrieve 19100 tweets\n",
      "retrieve 19200 tweets\n",
      "retrieve 19300 tweets\n",
      "retrieve 19400 tweets\n",
      "retrieve 19500 tweets\n",
      "retrieve 19600 tweets\n",
      "retrieve 19700 tweets\n",
      "retrieve 19800 tweets\n",
      "retrieve 19900 tweets\n",
      "retrieve 20000 tweets\n",
      "retrieve 20100 tweets\n",
      "retrieve 20200 tweets\n",
      "retrieve 20300 tweets\n",
      "retrieve 20400 tweets\n",
      "retrieve 20500 tweets\n",
      "retrieve 20600 tweets\n",
      "retrieve 20700 tweets\n",
      "retrieve 20800 tweets\n",
      "retrieve 20900 tweets\n",
      "retrieve 21000 tweets\n",
      "retrieve 21100 tweets\n",
      "retrieve 21200 tweets\n",
      "retrieve 21300 tweets\n",
      "retrieve 21400 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 21500 tweets\n",
      "retrieve 21600 tweets\n",
      "retrieve 21700 tweets\n",
      "retrieve 21800 tweets\n",
      "retrieve 21900 tweets\n",
      "retrieve 22000 tweets\n",
      "retrieve 22100 tweets\n",
      "retrieve 22200 tweets\n",
      "retrieve 22300 tweets\n",
      "retrieve 22400 tweets\n",
      "retrieve 22500 tweets\n",
      "retrieve 22600 tweets\n",
      "retrieve 22700 tweets\n",
      "retrieve 22800 tweets\n",
      "retrieve 22900 tweets\n",
      "retrieve 23000 tweets\n",
      "retrieve 23100 tweets\n",
      "retrieve 23200 tweets\n",
      "retrieve 23300 tweets\n",
      "retrieve 23400 tweets\n",
      "retrieve 23500 tweets\n",
      "retrieve 23600 tweets\n",
      "retrieve 23700 tweets\n",
      "retrieve 23800 tweets\n",
      "retrieve 23900 tweets\n",
      "retrieve 24000 tweets\n",
      "retrieve 24100 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 24200 tweets\n",
      "retrieve 24300 tweets\n",
      "retrieve 24400 tweets\n",
      "retrieve 24500 tweets\n",
      "retrieve 24600 tweets\n",
      "retrieve 24700 tweets\n",
      "retrieve 24800 tweets\n",
      "retrieve 24900 tweets\n",
      "retrieve 25000 tweets\n",
      "retrieve 25100 tweets\n",
      "retrieve 25200 tweets\n",
      "retrieve 25300 tweets\n",
      "retrieve 25400 tweets\n",
      "retrieve 25500 tweets\n",
      "retrieve 25600 tweets\n",
      "retrieve 25700 tweets\n",
      "retrieve 25800 tweets\n",
      "retrieve 25900 tweets\n",
      "retrieve 26000 tweets\n",
      "retrieve 26100 tweets\n",
      "retrieve 26200 tweets\n",
      "retrieve 26300 tweets\n",
      "retrieve 26400 tweets\n",
      "retrieve 26500 tweets\n",
      "retrieve 26600 tweets\n",
      "retrieve 26700 tweets\n",
      "retrieve 26800 tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieve 26900 tweets\n",
      "retrieve 27000 tweets\n",
      "retrieve 27100 tweets\n",
      "retrieve 27200 tweets\n",
      "retrieve 27300 tweets\n",
      "retrieve 27400 tweets\n",
      "retrieve 27500 tweets\n",
      "retrieve 27600 tweets\n",
      "retrieve 27700 tweets\n"
     ]
    }
   ],
   "source": [
    "keys = [\n",
    "#     'covid19uruguay', \n",
    "#     'covid19',\n",
    "#     'covid_19',\n",
    "#     'quedateencasa',\n",
    "#     'covid',\n",
    "#     'coronavirus',\n",
    "    'cuarentena',\n",
    "#     'coronavirusenuruguay'\n",
    "]\n",
    "\n",
    "full_dataset = []\n",
    "for key in keys:\n",
    "    ts = datetime.now().isoformat()\n",
    "    with open(f'../data/raw/uy_tweets_{key}_{ts}.json', 'w') as f:\n",
    "        json.dump(search_word(key, latitide=latitide, longitude=longitude, radius=radius), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "pprint(tweets[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friend = '@n_fornasari'\n",
    "for tweet in tweepy.Cursor(api.search, q=friend).items(10):\n",
    "    print(tweet.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
